{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "551884af",
   "metadata": {},
   "source": [
    "# ğŸš€ Focoos Edge Model Testing Notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcb4bca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“„ Loaded environment variables from: /Users/u464645/Documents/projects/hackatons/project/sample/.env\n",
      "âœ… Environment setup complete!\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import time\n",
    "\n",
    "\n",
    "# Load the trained model from edge_output (relative to workspace root)\n",
    "# Find workspace root by looking for pyproject.toml or .git directory\n",
    "def find_workspace_root():\n",
    "    \"\"\"Find the workspace root directory.\"\"\"\n",
    "    current_path = Path.cwd()\n",
    "    \n",
    "    # Look for workspace indicators\n",
    "    for path in [current_path] + list(current_path.parents):\n",
    "        if (path / \"pyproject.toml\").exists() or (path / \".git\").exists() or (path / \"README.md\").exists():\n",
    "            return path\n",
    "    \n",
    "    # Fallback to current directory\n",
    "    return current_path\n",
    "\n",
    "# Add project root to path for imports\n",
    "project_root = find_workspace_root()\n",
    "\n",
    "# Load environment variables\n",
    "try:\n",
    "    from dotenv import load_dotenv\n",
    "    env_path = project_root / \".env\"\n",
    "    if env_path.exists():\n",
    "        load_dotenv(env_path)\n",
    "        print(f\"ğŸ“„ Loaded environment variables from: {env_path}\")\n",
    "    else:\n",
    "        print(\"âš ï¸  .env file not found\")\n",
    "except ImportError:\n",
    "    print(\"ğŸ’¡ Install python-dotenv: pip install python-dotenv\")\n",
    "\n",
    "print(\"âœ… Environment setup complete!\")\n",
    "\n",
    "workspace_root = find_workspace_root()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c55c21ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ  Workspace root: /Users/u464645/Documents/projects/hackatons/project/sample\n",
      "ğŸ” Looking for model at: /Users/u464645/Documents/projects/hackatons/project/sample/edge_output/model.onnx\n",
      "âŒ Model not found at: /Users/u464645/Documents/projects/hackatons/project/sample/edge_output/model.onnx\n",
      "ğŸ’¡ Run training first from workspace root:\n",
      "   source .venv/bin/activate && python src/workflows/edge_workflow.py --model fai-cls-n-coco --task classification --dataset rock-paper-scissors-classification\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "workspace_root = find_workspace_root()\n",
    "model_path = workspace_root / \"edge_output\" / \"model.onnx\"\n",
    "\n",
    "print(f\"ğŸ  Workspace root: {workspace_root}\")\n",
    "print(f\"ğŸ” Looking for model at: {model_path}\")\n",
    "\n",
    "if model_path.exists():\n",
    "    print(f\"âœ… Found trained model at: {model_path}\")\n",
    "    \n",
    "    # Import Focoos inference\n",
    "    try:\n",
    "        from focoos import InferModel\n",
    "        from focoos.ports import DatasetLayout, RuntimeType, Task\n",
    "\n",
    "        # Load the exported TorchScript model\n",
    "        print(\"ğŸ“¥ Loading trained edge model...\")\n",
    "        model = InferModel(str(model_path), runtime_type=RuntimeType.ONNX_CPU)  # Convert Path to string for InferModel\n",
    "        print(\"âœ… Model loaded successfully!\")\n",
    "        \n",
    "        # Display model info\n",
    "        print(f\"\\nğŸ“Š Model Information:\")\n",
    "        print(f\"   Model file: {model_path}\")\n",
    "        print(f\"   File size: {model_path.stat().st_size / 1024:.1f} KB\")\n",
    "        print(f\"   Runtime: TorchScript (edge-optimized)\")\n",
    "        print(f\"   Target device: Arduino Nicla Vision\")\n",
    "        \n",
    "    except ImportError as e:\n",
    "        print(f\"âŒ Import error: {e}\")\n",
    "        print(\"ğŸ’¡ Make sure focoos is installed: pip install focoos\")\n",
    "        model = None\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Failed to load model: {e}\")\n",
    "        model = None\n",
    "        \n",
    "else:\n",
    "    print(f\"âŒ Model not found at: {model_path}\")\n",
    "    print(\"ğŸ’¡ Run training first from workspace root:\")\n",
    "    print(\"   source .venv/bin/activate && python src/workflows/edge_workflow.py --model fai-cls-n-coco --task classification --dataset rock-paper-scissors-classification\")\n",
    "    model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91049977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Available Datasets:\n",
      "==================================================\n",
      "\n",
      "ğŸ“ emotions_back\n",
      "   ğŸ“‹ Train classes (3): ['background', 'tired-person', 'happy-person']\n",
      "   ğŸ–¼ï¸  Total images: 5725\n",
      "\n",
      "ğŸ“ human_identification_only\n",
      "   ğŸ“‹ Train classes (1): ['humans']\n",
      "   ğŸ–¼ï¸  Total images: 1260\n",
      "\n",
      "ğŸ“ Face emotion classification.v3i.folder\n",
      "   ğŸ“‹ Train classes (3): ['background', 'tired-person', 'happy-person']\n",
      "   ğŸ–¼ï¸  Total images: 1346\n",
      "\n",
      "ğŸ“ emotions_original\n",
      "   ğŸ“‹ Train classes (5): ['Happy', 'Sad', 'Surprise', 'Neutral', 'Angry']\n",
      "   ğŸ–¼ï¸  Total images: 9768\n",
      "\n",
      "ğŸ“ human_identification_balanced\n",
      "   ğŸ“‹ Train classes (2): ['background', 'humans']\n",
      "   ğŸ–¼ï¸  Total images: 2560\n",
      "\n",
      "ğŸ“ human_identification_merged\n",
      "   ğŸ“‹ Train classes (2): ['background', 'human']\n",
      "   ğŸ–¼ï¸  Total images: 3819\n",
      "\n",
      "ğŸ“ emotions\n",
      "   ğŸ“‹ Train classes (2): ['tired-person', 'happy-person']\n",
      "   ğŸ–¼ï¸  Total images: 3788\n"
     ]
    }
   ],
   "source": [
    "# Show available datasets and their structure (from workspace root)\n",
    "def show_available_datasets():\n",
    "    \"\"\"Display all available datasets and their structure.\"\"\"\n",
    "    # Use workspace root to find datasets directory\n",
    "    datasets_base = workspace_root / \"datasets\"\n",
    "    \n",
    "    if not datasets_base.exists():\n",
    "        print(\"ğŸ“ No datasets directory found at workspace root\")\n",
    "        print(f\"   Expected: {datasets_base}\")\n",
    "        return\n",
    "    \n",
    "    print(\"ğŸ“Š Available Datasets:\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    for dataset_folder in datasets_base.iterdir():\n",
    "        if dataset_folder.is_dir():\n",
    "            print(f\"\\nğŸ“ {dataset_folder.name}\")\n",
    "            \n",
    "            # Check dataset structure\n",
    "            train_paths = list(dataset_folder.rglob(\"train\"))\n",
    "            if train_paths:\n",
    "                for train_path in train_paths:\n",
    "                    class_dirs = [d for d in train_path.iterdir() if d.is_dir()]\n",
    "                    if class_dirs:\n",
    "                        print(f\"   ğŸ“‹ Train classes ({len(class_dirs)}): {[d.name for d in class_dirs[:5]]}\")\n",
    "                        if len(class_dirs) > 5:\n",
    "                            print(f\"       ... and {len(class_dirs)-5} more\")\n",
    "                        \n",
    "                        # Count images\n",
    "                        image_count = len([f for f in train_path.rglob(\"*.jpg\")] + \n",
    "                                        [f for f in train_path.rglob(\"*.jpeg\")] + \n",
    "                                        [f for f in train_path.rglob(\"*.png\")])\n",
    "                        print(f\"   ğŸ–¼ï¸  Total images: {image_count}\")\n",
    "                    else:\n",
    "                        print(f\"   âŒ No class directories found in {train_path}\")\n",
    "            else:\n",
    "                print(\"   âŒ No train directory found\")\n",
    "\n",
    "show_available_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fec7a059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Looking for datasets in: /Users/u464645/Documents/projects/hackatons/project/sample/datasets\n",
      "ğŸ“ Checking dataset: emotions_back\n",
      "   âœ… Found training data: /Users/u464645/Documents/projects/hackatons/project/sample/datasets/emotions_back/train\n",
      "ğŸ“ Checking dataset: human_identification_only\n",
      "   âœ… Found training data: /Users/u464645/Documents/projects/hackatons/project/sample/datasets/human_identification_only/train\n",
      "ğŸ“ Checking dataset: Face emotion classification.v3i.folder\n",
      "   âœ… Found training data: /Users/u464645/Documents/projects/hackatons/project/sample/datasets/Face emotion classification.v3i.folder/train\n",
      "ğŸ“ Checking dataset: emotions_original\n",
      "   âœ… Found training data: /Users/u464645/Documents/projects/hackatons/project/sample/datasets/emotions_original/train\n",
      "ğŸ“ Checking dataset: human_identification_balanced\n",
      "   âœ… Found training data: /Users/u464645/Documents/projects/hackatons/project/sample/datasets/human_identification_balanced/train\n",
      "ğŸ“ Checking dataset: human_identification_merged\n",
      "   âœ… Found training data: /Users/u464645/Documents/projects/hackatons/project/sample/datasets/human_identification_merged/train\n",
      "ğŸ“ Checking dataset: emotions\n",
      "   âœ… Found training data: /Users/u464645/Documents/projects/hackatons/project/sample/datasets/emotions/train\n",
      "ğŸ“Š Found 28606 test images across 1 classes\n",
      "ğŸ“‹ Classes found: ['background']\n",
      "   background: 350 images\n"
     ]
    }
   ],
   "source": [
    "# Get test images from the extracted datasets (relative to workspace root)\n",
    "def find_dataset_images():\n",
    "    \"\"\"Find test images from extracted datasets using workspace root.\"\"\"\n",
    "    datasets_base = workspace_root / \"datasets\"\n",
    "    test_images = []\n",
    "    classes = {}\n",
    "    \n",
    "    if not datasets_base.exists():\n",
    "        print(f\"âŒ Datasets directory not found: {datasets_base}\")\n",
    "        return test_images, classes\n",
    "    \n",
    "    print(f\"ğŸ” Looking for datasets in: {datasets_base}\")\n",
    "    \n",
    "    # Look through all dataset directories\n",
    "    for dataset_folder in datasets_base.iterdir():\n",
    "        if dataset_folder.is_dir():\n",
    "            print(f\"ğŸ“ Checking dataset: {dataset_folder.name}\")\n",
    "            \n",
    "            # Look for train directories in various possible structures\n",
    "            possible_train_paths = [\n",
    "                dataset_folder / \"train\",  # Direct structure\n",
    "                dataset_folder / dataset_folder.name / \"train\",  # Nested with same name\n",
    "            ]\n",
    "            \n",
    "            # Also check for any subdirectory that contains train/\n",
    "            for subdir in dataset_folder.rglob(\"train\"):\n",
    "                if subdir.is_dir():\n",
    "                    possible_train_paths.append(subdir)\n",
    "            \n",
    "            for train_path in possible_train_paths:\n",
    "                if train_path.exists() and train_path.is_dir():\n",
    "                    print(f\"   âœ… Found training data: {train_path}\")\n",
    "                    \n",
    "                    # Find image files\n",
    "                    image_extensions = {'.jpg', '.jpeg', '.png', '.bmp'}\n",
    "                    \n",
    "                    for img_path in train_path.rglob(\"*\"):\n",
    "                        if img_path.suffix.lower() in image_extensions and img_path.is_file():\n",
    "                            test_images.append(img_path)\n",
    "                    \n",
    "                    # Group by class (parent directory name)\n",
    "                    for img_path in test_images[:50]:  # Limit to first 50 for display\n",
    "                        class_name = img_path.parent.name\n",
    "                        if class_name not in classes:\n",
    "                            classes[class_name] = []\n",
    "                        classes[class_name].append(img_path)\n",
    "                    \n",
    "                    break  # Use first valid train directory found\n",
    "    \n",
    "    return test_images, classes\n",
    "\n",
    "# Find images from the datasets\n",
    "test_images, classes = find_dataset_images()\n",
    "\n",
    "if test_images:\n",
    "    print(f\"ğŸ“Š Found {len(test_images)} test images across {len(classes)} classes\")\n",
    "    print(f\"ğŸ“‹ Classes found: {list(classes.keys())}\")\n",
    "    for class_name, images in classes.items():\n",
    "        print(f\"   {class_name}: {len(images)} images\")\n",
    "else:\n",
    "    print(\"âŒ No test images found\")\n",
    "    print(\"ğŸ’¡ Make sure you've run training to extract a dataset:\")\n",
    "    print(\"   cd\", workspace_root)\n",
    "    print(\"   source .venv/bin/activate && python src/workflows/edge_workflow.py --model fai-cls-n-coco --task classification --dataset rock-paper-scissors-classification --max_iters 100\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a4572a",
   "metadata": {},
   "source": [
    "## ğŸ§ª Interactive Testing\n",
    "\n",
    "Now let's test the model with sample images! Run the cells below to test different images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c3dec43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from datetime import datetime\n",
    "from PIL import Image\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "def interactive_webcam_tester(model, classes, preferred_label,workspace_root, window_name=\"Webcam Tester - Press SPACE to test, Q to quit\"):\n",
    "    \"\"\"Interactive webcam tester - capture images and run tests when prompted.\"\"\"\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    if not cap.isOpened():\n",
    "        print(\"âŒ Could not open webcam.\")\n",
    "        return\n",
    "\n",
    "    print(\"ğŸ“¸ Interactive Webcam Tester Started!\")\n",
    "    print(\"Controls:\")\n",
    "    print(\"  - SPACEBAR: Capture image and run test\")\n",
    "    print(\"  - 'q': Quit\")\n",
    "    print(\"  - ESC: Quit\")\n",
    "    \n",
    "    class_list = sorted(list(classes.keys())) if classes else None\n",
    "    capture_count = 0\n",
    "    \n",
    "    # Create directory for captured images\n",
    "    captures_dir = Path(workspace_root) / \"webcam_captures\"\n",
    "    captures_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    # Variables to store prediction results - IMPROVED SYNCHRONIZATION\n",
    "    current_prediction = None\n",
    "    current_confidence = 0.0\n",
    "    prediction_timestamp = None\n",
    "    is_processing = False  # Flag to show when inference is running\n",
    "    processing_start = None\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"âš ï¸ Failed to grab frame.\")\n",
    "            break\n",
    "\n",
    "        height, width = frame.shape[:2]\n",
    "        \n",
    "        # Add instructions overlay\n",
    "        instructions = [\n",
    "            \"Press SPACE to capture & test\",\n",
    "            \"Press Q to quit\"\n",
    "        ]\n",
    "        \n",
    "        # Show processing status\n",
    "        if is_processing:\n",
    "            instructions.append(\"ğŸ”„ Processing... Please wait\")\n",
    "        \n",
    "        for i, text in enumerate(instructions):\n",
    "            y_pos = 30 + (i * 30)\n",
    "            color = (0, 165, 255) if \"Processing\" in text else (0, 255, 255)  # Orange for processing\n",
    "            cv2.putText(frame, text, (10, y_pos), cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)\n",
    "\n",
    "        # Show crosshair for better framing\n",
    "        cv2.line(frame, (width//2 - 20, height//2), (width//2 + 20, height//2), (0, 255, 0), 2)\n",
    "        cv2.line(frame, (width//2, height//2 - 20), (width//2, height//2 + 20), (0, 255, 0), 2)\n",
    "\n",
    "        # Display CURRENT prediction result (synchronized with latest inference)\n",
    "        if current_prediction is not None and prediction_timestamp:\n",
    "            elapsed = datetime.now() - prediction_timestamp\n",
    "            if elapsed.total_seconds() < 15:  # Show prediction for 15 seconds\n",
    "                # Create a semi-transparent overlay for better text visibility\n",
    "                overlay = frame.copy()\n",
    "                cv2.rectangle(overlay, (10, height - 140), (width - 10, height - 10), (0, 0, 0), -1)\n",
    "                cv2.addWeighted(overlay, 0.7, frame, 0.3, 0, frame)\n",
    "                \n",
    "                # Display prediction result with FRESH indicator\n",
    "                pred_text = f\"Latest: {current_prediction}\"\n",
    "                conf_text = f\"Confidence: {current_confidence:.3f}\"\n",
    "                time_text = f\"Age: {elapsed.total_seconds():.1f}s\"\n",
    "                \n",
    "                # Choose color based on confidence and freshness\n",
    "                if elapsed.total_seconds() < 2:  # Fresh prediction (< 2 seconds)\n",
    "                    color = (0, 255, 0) if current_confidence > 0.7 else (0, 255, 255)  # Bright green/cyan\n",
    "                    fresh_indicator = \"ğŸ†• FRESH\"\n",
    "                else:\n",
    "                    color = (128, 255, 128) if current_confidence > 0.7 else (128, 255, 255)  # Dimmer colors\n",
    "                    fresh_indicator = \"\"\n",
    "                \n",
    "                cv2.putText(frame, pred_text, (20, height - 110), cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 2)\n",
    "                cv2.putText(frame, conf_text, (20, height - 80), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "                cv2.putText(frame, time_text, (20, height - 50), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "                \n",
    "                if fresh_indicator:\n",
    "                    cv2.putText(frame, fresh_indicator, (20, height - 25), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "        cv2.imshow(window_name, frame)\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        \n",
    "        if key == ord('q') or key == 27:  # 'q' or ESC key\n",
    "            break\n",
    "        elif key == ord(' ') and not is_processing:  # Spacebar - only if not already processing\n",
    "            # START PROCESSING - Set flags IMMEDIATELY\n",
    "            is_processing = True\n",
    "            processing_start = datetime.now()\n",
    "            \n",
    "            # Capture and test the current frame\n",
    "            capture_count += 1\n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            \n",
    "            print(f\"\\nğŸ“¸ Capture #{capture_count} - Running test...\")\n",
    "            \n",
    "            # Save the captured frame FIRST\n",
    "            capture_filename = f\"capture_{capture_count}_{timestamp}.jpg\"\n",
    "            capture_path = captures_dir / capture_filename\n",
    "            cv2.imwrite(str(capture_path), frame)\n",
    "            print(f\"ğŸ’¾ Saved image: {capture_path}\")\n",
    "            \n",
    "            # Convert frame to RGB for model inference\n",
    "            rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            pil_image = Image.fromarray(rgb_frame)\n",
    "            \n",
    "            # CLEAR OLD PREDICTION before starting new inference\n",
    "            current_prediction = \"Processing...\"\n",
    "            current_confidence = 0.0\n",
    "            prediction_timestamp = datetime.now()\n",
    "            \n",
    "            # Run inference on the captured frame\n",
    "            try:\n",
    "                start_time = time.time()\n",
    "                \n",
    "                # Try different input formats\n",
    "                try:\n",
    "                    result = model.infer(image=pil_image, threshold=0.4, annotate=False)\n",
    "                except Exception:\n",
    "                    try:\n",
    "                        result = model.infer(image=str(capture_path), threshold=0.4, annotate=False)\n",
    "                    except Exception:\n",
    "                        result = model(pil_image)\n",
    "                \n",
    "                inference_time = time.time() - start_time\n",
    "                # Parse results and update display variables IMMEDIATELY\n",
    "                # Extract the detection with highest confidence\n",
    "\n",
    "                print(result.__dict__)\n",
    "                \n",
    "                if result.detections:\n",
    "                    detections = result.detections\n",
    "                    humans_detections = [d for d in detections if d.label == preferred_label and d.conf > 0.5]\n",
    "                    if humans_detections:\n",
    "                        # Prioritize humans if confidence > 0.5, use the best humans detection\n",
    "                        best_humans = max(humans_detections, key=lambda x: x.conf)\n",
    "                        label = best_humans.label\n",
    "                        conf = best_humans.conf\n",
    "                    else:\n",
    "                        # Otherwise use the detection with highest confidence overall\n",
    "                        best_detection = max(detections, key=lambda x: x.conf)\n",
    "                        label = best_detection.label\n",
    "                        conf = best_detection.conf\n",
    "                    \n",
    "                    print(f\"   âœ… Prediction: {label} (confidence: {conf:.3f})\")\n",
    "                    detections = result.detections\n",
    "                 \n",
    "                else:\n",
    "                    label = str(result)\n",
    "                    conf = 0.0\n",
    "\n",
    "\n",
    "\n",
    "                current_prediction = label\n",
    "                current_confidence = conf\n",
    "                prediction_timestamp = datetime.now()  # Fresh timestamp for new prediction\n",
    "                \n",
    "                print(f\"â±ï¸  Inference time: {inference_time*1000:.1f} ms\")\n",
    "                print(f\"ğŸ’¾ Image saved as: {capture_filename}\")\n",
    "                print(f\"âœ… NEW prediction updated: {label} ({conf:.3f})\")\n",
    "                print(\"-\" * 50)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"âŒ Inference error: {e}\")\n",
    "                current_prediction = \"ERROR\"\n",
    "                current_confidence = 0.0\n",
    "                prediction_timestamp = datetime.now()\n",
    "                print(\"-\" * 50)\n",
    "            \n",
    "            # FINISH PROCESSING - Clear flag\n",
    "            is_processing = False\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(f\"ğŸ›‘ Webcam tester stopped. Captured {capture_count} images.\")\n",
    "    if capture_count > 0:\n",
    "        print(f\"ğŸ“ Images saved in: {captures_dir}\")\n",
    "\n",
    "def batch_test_captures(model, workspace_root, preferred_label, classes=None):\n",
    "    \"\"\"Test all previously captured images.\"\"\"\n",
    "    captures_dir = Path(workspace_root) / \"webcam_captures\"\n",
    "    \n",
    "    if not captures_dir.exists():\n",
    "        print(\"âŒ No captures directory found. Capture some images first!\")\n",
    "        return\n",
    "    \n",
    "    image_files = list(captures_dir.glob(\"*.jpg\")) + list(captures_dir.glob(\"*.png\"))\n",
    "    \n",
    "    if not image_files:\n",
    "        print(\"âŒ No captured images found.\")\n",
    "        return\n",
    "    \n",
    "    print(f\"ğŸ§ª Testing {len(image_files)} captured images...\")\n",
    "    \n",
    "    for img_path in sorted(image_files):\n",
    "        print(f\"\\nğŸ“¸ Testing: {img_path.name}\")\n",
    "        # Test each image\n",
    "        try:\n",
    "            result = model.infer(image=str(img_path), threshold=0.5, annotate=False)\n",
    "            \n",
    "            # Parse results\n",
    "            if isinstance(result, dict) and \"detections\" in result:\n",
    "                detections = result[\"detections\"]\n",
    "                if detections:\n",
    "                    # Check for high-confidence humans detection first\n",
    "                    humans_detections = [d for d in detections if d.label == preferred_label and d.conf > 0.5]\n",
    "                    print(detections.__dict__)\n",
    "                    if humans_detections:\n",
    "                        # Prioritize humans if confidence > 0.5, use the best humans detection\n",
    "                        best_humans = max(humans_detections, key=lambda x: x.conf)\n",
    "                        label = best_humans.label\n",
    "                        conf = best_humans.conf\n",
    "                    else:\n",
    "                        # Otherwise use the detection with highest confidence overall\n",
    "                        best_detection = max(detections, key=lambda x: x.conf)\n",
    "                        label = best_detection.label\n",
    "                        conf = best_detection.conf\n",
    "                    \n",
    "                    print(f\"   âœ… Prediction: {label} (confidence: {conf:.3f})\")\n",
    "                else:\n",
    "                    print(f\"   âš ï¸ No detections found\")\n",
    "            else:\n",
    "                print(f\"   â„¹ï¸ Result: {result}\")\n",
    "        except Exception as e:\n",
    "            print(f\"   âŒ Error: {e}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df42348",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;32m[10/05 02:52][INFO][HUB]: Currently logged as: frigato.luca97@gmail.com environment: https://api.focoos.ai/v0\u001b[0m\n",
      "\u001b[1;32m[10/05 02:52][INFO][HUB]: ğŸ“¥ Model already downloaded\u001b[0m\n",
      "\u001b[1;32m[10/05 02:52][INFO][ModelManager]: ğŸ“¥ Loading model info from cache: /Users/u464645/FocoosAI/models/af0de65d2173413e/model_info.json\u001b[0m\n",
      "\u001b[1;35m[10/05 02:52][WARNING][Backbone]: Layers must be [2, 2, 2] if size is nano, provided [4, 5, 3] not used.\u001b[0m\n",
      "\u001b[1;35m[10/05 02:52][WARNING][Backbone]: Base must be 32 if size is nano, provided 64 not used.\u001b[0m\n",
      "\u001b[1;35m[10/05 02:52][WARNING][FocoosModel]: Unable to use CUDA\u001b[0m\n",
      "\u001b[1;32m[10/05 02:52][INFO][FocoosModel]: Loading weights from local path: /Users/u464645/FocoosAI/models/af0de65d2173413e/model_final.pth\u001b[0m\n",
      "UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” HUB Model Status:\n",
      "âœ… HUB Model loaded: <class 'focoos.models.focoos_model.FocoosModel'>\n",
      "ğŸ“¸ Interactive Webcam Tester Started!\n",
      "Controls:\n",
      "  - SPACEBAR: Capture image and run test\n",
      "  - 'q': Quit\n",
      "  - ESC: Quit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-05 02:52:13.024 python[38289:11955490] +[IMKClient subclass]: chose IMKClient_Modern\n",
      "2025-10-05 02:52:13.024 python[38289:11955490] +[IMKInputSession subclass]: chose IMKInputSession_Modern\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“¸ Capture #1 - Running test...\n",
      "ğŸ’¾ Saved image: /Users/u464645/Documents/projects/hackatons/project/sample/webcam_captures/capture_1_20251005_025213.jpg\n",
      "\n",
      "1 happy-person, 1 tired-person\n",
      "Latency: imload 2ms, preprocess 3ms, inference 23ms, postprocess 0ms, total 28ms\n",
      "{'detections': [FocoosDet(bbox=None, conf=0.6550604104995728, cls_id=0, label=happy-person, mask=None, keypoints=None), FocoosDet(bbox=None, conf=0.7397279739379883, cls_id=1, label=tired-person, mask=None, keypoints=None)], 'image': None, 'latency': InferLatency(imload=0.002, preprocess=0.003, inference=0.023, postprocess=0.0, annotate=None)}\n",
      "   âœ… Prediction: tired-person (confidence: 0.740)\n",
      "â±ï¸  Inference time: 28.3 ms\n",
      "ğŸ’¾ Image saved as: capture_1_20251005_025213.jpg\n",
      "âœ… NEW prediction updated: tired-person (0.740)\n",
      "--------------------------------------------------\n",
      "\n",
      "ğŸ“¸ Capture #2 - Running test...\n",
      "ğŸ’¾ Saved image: /Users/u464645/Documents/projects/hackatons/project/sample/webcam_captures/capture_2_20251005_025213.jpg\n",
      "\n",
      "1 happy-person, 1 tired-person\n",
      "Latency: imload 2ms, preprocess 1ms, inference 22ms, postprocess 0ms, total 25ms\n",
      "{'detections': [FocoosDet(bbox=None, conf=0.6968701481819153, cls_id=0, label=happy-person, mask=None, keypoints=None), FocoosDet(bbox=None, conf=0.7156947255134583, cls_id=1, label=tired-person, mask=None, keypoints=None)], 'image': None, 'latency': InferLatency(imload=0.002, preprocess=0.001, inference=0.022, postprocess=0.0, annotate=None)}\n",
      "   âœ… Prediction: tired-person (confidence: 0.716)\n",
      "â±ï¸  Inference time: 26.1 ms\n",
      "ğŸ’¾ Image saved as: capture_2_20251005_025213.jpg\n",
      "âœ… NEW prediction updated: tired-person (0.716)\n",
      "--------------------------------------------------\n",
      "\n",
      "ğŸ“¸ Capture #3 - Running test...\n",
      "ğŸ’¾ Saved image: /Users/u464645/Documents/projects/hackatons/project/sample/webcam_captures/capture_3_20251005_025214.jpg\n",
      "\n",
      "1 happy-person, 1 tired-person\n",
      "Latency: imload 2ms, preprocess 1ms, inference 24ms, postprocess 0ms, total 27ms\n",
      "{'detections': [FocoosDet(bbox=None, conf=0.6827651262283325, cls_id=0, label=happy-person, mask=None, keypoints=None), FocoosDet(bbox=None, conf=0.7196367979049683, cls_id=1, label=tired-person, mask=None, keypoints=None)], 'image': None, 'latency': InferLatency(imload=0.002, preprocess=0.001, inference=0.024, postprocess=0.0, annotate=None)}\n",
      "   âœ… Prediction: tired-person (confidence: 0.720)\n",
      "â±ï¸  Inference time: 27.1 ms\n",
      "ğŸ’¾ Image saved as: capture_3_20251005_025214.jpg\n",
      "âœ… NEW prediction updated: tired-person (0.720)\n",
      "--------------------------------------------------\n",
      "\n",
      "ğŸ“¸ Capture #4 - Running test...\n",
      "ğŸ’¾ Saved image: /Users/u464645/Documents/projects/hackatons/project/sample/webcam_captures/capture_4_20251005_025215.jpg\n",
      "\n",
      "1 happy-person, 1 tired-person\n",
      "Latency: imload 2ms, preprocess 1ms, inference 22ms, postprocess 0ms, total 25ms\n",
      "{'detections': [FocoosDet(bbox=None, conf=0.7342789173126221, cls_id=0, label=happy-person, mask=None, keypoints=None), FocoosDet(bbox=None, conf=0.6709330677986145, cls_id=1, label=tired-person, mask=None, keypoints=None)], 'image': None, 'latency': InferLatency(imload=0.002, preprocess=0.001, inference=0.022, postprocess=0.0, annotate=None)}\n",
      "   âœ… Prediction: tired-person (confidence: 0.671)\n",
      "â±ï¸  Inference time: 24.7 ms\n",
      "ğŸ’¾ Image saved as: capture_4_20251005_025215.jpg\n",
      "âœ… NEW prediction updated: tired-person (0.671)\n",
      "--------------------------------------------------\n",
      "\n",
      "ğŸ“¸ Capture #5 - Running test...\n",
      "ğŸ’¾ Saved image: /Users/u464645/Documents/projects/hackatons/project/sample/webcam_captures/capture_5_20251005_025215.jpg\n",
      "\n",
      "1 happy-person, 1 tired-person\n",
      "Latency: imload 2ms, preprocess 2ms, inference 22ms, postprocess 0ms, total 26ms\n",
      "{'detections': [FocoosDet(bbox=None, conf=0.7184049487113953, cls_id=0, label=happy-person, mask=None, keypoints=None), FocoosDet(bbox=None, conf=0.6891725063323975, cls_id=1, label=tired-person, mask=None, keypoints=None)], 'image': None, 'latency': InferLatency(imload=0.002, preprocess=0.002, inference=0.022, postprocess=0.0, annotate=None)}\n",
      "   âœ… Prediction: tired-person (confidence: 0.689)\n",
      "â±ï¸  Inference time: 26.6 ms\n",
      "ğŸ’¾ Image saved as: capture_5_20251005_025215.jpg\n",
      "âœ… NEW prediction updated: tired-person (0.689)\n",
      "--------------------------------------------------\n",
      "\n",
      "ğŸ“¸ Capture #6 - Running test...\n",
      "ğŸ’¾ Saved image: /Users/u464645/Documents/projects/hackatons/project/sample/webcam_captures/capture_6_20251005_025215.jpg\n",
      "\n",
      "1 happy-person, 1 tired-person\n",
      "Latency: imload 2ms, preprocess 1ms, inference 23ms, postprocess 0ms, total 26ms\n",
      "{'detections': [FocoosDet(bbox=None, conf=0.7692765593528748, cls_id=0, label=happy-person, mask=None, keypoints=None), FocoosDet(bbox=None, conf=0.6563300490379333, cls_id=1, label=tired-person, mask=None, keypoints=None)], 'image': None, 'latency': InferLatency(imload=0.002, preprocess=0.001, inference=0.023, postprocess=0.0, annotate=None)}\n",
      "   âœ… Prediction: tired-person (confidence: 0.656)\n",
      "â±ï¸  Inference time: 25.6 ms\n",
      "ğŸ’¾ Image saved as: capture_6_20251005_025215.jpg\n",
      "âœ… NEW prediction updated: tired-person (0.656)\n",
      "--------------------------------------------------\n",
      "\n",
      "ğŸ“¸ Capture #7 - Running test...\n",
      "ğŸ’¾ Saved image: /Users/u464645/Documents/projects/hackatons/project/sample/webcam_captures/capture_7_20251005_025216.jpg\n",
      "\n",
      "1 happy-person, 1 tired-person\n",
      "Latency: imload 2ms, preprocess 1ms, inference 23ms, postprocess 0ms, total 26ms\n",
      "{'detections': [FocoosDet(bbox=None, conf=0.7033926844596863, cls_id=0, label=happy-person, mask=None, keypoints=None), FocoosDet(bbox=None, conf=0.6910528540611267, cls_id=1, label=tired-person, mask=None, keypoints=None)], 'image': None, 'latency': InferLatency(imload=0.002, preprocess=0.001, inference=0.023, postprocess=0.0, annotate=None)}\n",
      "   âœ… Prediction: tired-person (confidence: 0.691)\n",
      "â±ï¸  Inference time: 27.3 ms\n",
      "ğŸ’¾ Image saved as: capture_7_20251005_025216.jpg\n",
      "âœ… NEW prediction updated: tired-person (0.691)\n",
      "--------------------------------------------------\n",
      "\n",
      "ğŸ“¸ Capture #8 - Running test...\n",
      "ğŸ’¾ Saved image: /Users/u464645/Documents/projects/hackatons/project/sample/webcam_captures/capture_8_20251005_025217.jpg\n",
      "\n",
      "1 happy-person, 1 tired-person\n",
      "Latency: imload 3ms, preprocess 1ms, inference 22ms, postprocess 0ms, total 26ms\n",
      "{'detections': [FocoosDet(bbox=None, conf=0.6781244874000549, cls_id=0, label=happy-person, mask=None, keypoints=None), FocoosDet(bbox=None, conf=0.6880024075508118, cls_id=1, label=tired-person, mask=None, keypoints=None)], 'image': None, 'latency': InferLatency(imload=0.003, preprocess=0.001, inference=0.022, postprocess=0.0, annotate=None)}\n",
      "   âœ… Prediction: tired-person (confidence: 0.688)\n",
      "â±ï¸  Inference time: 26.3 ms\n",
      "ğŸ’¾ Image saved as: capture_8_20251005_025217.jpg\n",
      "âœ… NEW prediction updated: tired-person (0.688)\n",
      "--------------------------------------------------\n",
      "\n",
      "ğŸ“¸ Capture #9 - Running test...\n",
      "ğŸ’¾ Saved image: /Users/u464645/Documents/projects/hackatons/project/sample/webcam_captures/capture_9_20251005_025217.jpg\n",
      "\n",
      "1 happy-person, 1 tired-person\n",
      "Latency: imload 3ms, preprocess 1ms, inference 22ms, postprocess 0ms, total 26ms\n",
      "{'detections': [FocoosDet(bbox=None, conf=0.6910024881362915, cls_id=0, label=happy-person, mask=None, keypoints=None), FocoosDet(bbox=None, conf=0.6900596618652344, cls_id=1, label=tired-person, mask=None, keypoints=None)], 'image': None, 'latency': InferLatency(imload=0.003, preprocess=0.001, inference=0.022, postprocess=0.0, annotate=None)}\n",
      "   âœ… Prediction: tired-person (confidence: 0.690)\n",
      "â±ï¸  Inference time: 26.8 ms\n",
      "ğŸ’¾ Image saved as: capture_9_20251005_025217.jpg\n",
      "âœ… NEW prediction updated: tired-person (0.690)\n",
      "--------------------------------------------------\n",
      "\n",
      "ğŸ“¸ Capture #10 - Running test...\n",
      "ğŸ’¾ Saved image: /Users/u464645/Documents/projects/hackatons/project/sample/webcam_captures/capture_10_20251005_025218.jpg\n",
      "\n",
      "1 happy-person, 1 tired-person\n",
      "Latency: imload 2ms, preprocess 1ms, inference 23ms, postprocess 0ms, total 26ms\n",
      "{'detections': [FocoosDet(bbox=None, conf=0.6871628761291504, cls_id=0, label=happy-person, mask=None, keypoints=None), FocoosDet(bbox=None, conf=0.699068009853363, cls_id=1, label=tired-person, mask=None, keypoints=None)], 'image': None, 'latency': InferLatency(imload=0.002, preprocess=0.001, inference=0.023, postprocess=0.0, annotate=None)}\n",
      "   âœ… Prediction: tired-person (confidence: 0.699)\n",
      "â±ï¸  Inference time: 26.5 ms\n",
      "ğŸ’¾ Image saved as: capture_10_20251005_025218.jpg\n",
      "âœ… NEW prediction updated: tired-person (0.699)\n",
      "--------------------------------------------------\n",
      "\n",
      "ğŸ“¸ Capture #11 - Running test...\n",
      "ğŸ’¾ Saved image: /Users/u464645/Documents/projects/hackatons/project/sample/webcam_captures/capture_11_20251005_025218.jpg\n",
      "\n",
      "1 happy-person, 1 tired-person\n",
      "Latency: imload 2ms, preprocess 1ms, inference 22ms, postprocess 0ms, total 25ms\n",
      "{'detections': [FocoosDet(bbox=None, conf=0.6834681630134583, cls_id=0, label=happy-person, mask=None, keypoints=None), FocoosDet(bbox=None, conf=0.711013913154602, cls_id=1, label=tired-person, mask=None, keypoints=None)], 'image': None, 'latency': InferLatency(imload=0.002, preprocess=0.001, inference=0.022, postprocess=0.0, annotate=None)}\n",
      "   âœ… Prediction: tired-person (confidence: 0.711)\n",
      "â±ï¸  Inference time: 26.2 ms\n",
      "ğŸ’¾ Image saved as: capture_11_20251005_025218.jpg\n",
      "âœ… NEW prediction updated: tired-person (0.711)\n",
      "--------------------------------------------------\n",
      "\n",
      "ğŸ“¸ Capture #12 - Running test...\n",
      "ğŸ’¾ Saved image: /Users/u464645/Documents/projects/hackatons/project/sample/webcam_captures/capture_12_20251005_025219.jpg\n",
      "\n",
      "1 happy-person, 1 tired-person\n",
      "Latency: imload 2ms, preprocess 2ms, inference 23ms, postprocess 0ms, total 27ms\n",
      "{'detections': [FocoosDet(bbox=None, conf=0.7424031496047974, cls_id=0, label=happy-person, mask=None, keypoints=None), FocoosDet(bbox=None, conf=0.6564396023750305, cls_id=1, label=tired-person, mask=None, keypoints=None)], 'image': None, 'latency': InferLatency(imload=0.002, preprocess=0.002, inference=0.023, postprocess=0.0, annotate=None)}\n",
      "   âœ… Prediction: tired-person (confidence: 0.656)\n",
      "â±ï¸  Inference time: 27.6 ms\n",
      "ğŸ’¾ Image saved as: capture_12_20251005_025219.jpg\n",
      "âœ… NEW prediction updated: tired-person (0.656)\n",
      "--------------------------------------------------\n",
      "\n",
      "ğŸ“¸ Capture #13 - Running test...\n",
      "ğŸ’¾ Saved image: /Users/u464645/Documents/projects/hackatons/project/sample/webcam_captures/capture_13_20251005_025219.jpg\n",
      "\n",
      "1 happy-person, 1 tired-person\n",
      "Latency: imload 2ms, preprocess 2ms, inference 22ms, postprocess 0ms, total 26ms\n",
      "{'detections': [FocoosDet(bbox=None, conf=0.6544747352600098, cls_id=0, label=happy-person, mask=None, keypoints=None), FocoosDet(bbox=None, conf=0.7064234018325806, cls_id=1, label=tired-person, mask=None, keypoints=None)], 'image': None, 'latency': InferLatency(imload=0.002, preprocess=0.002, inference=0.022, postprocess=0.0, annotate=None)}\n",
      "   âœ… Prediction: tired-person (confidence: 0.706)\n",
      "â±ï¸  Inference time: 26.3 ms\n",
      "ğŸ’¾ Image saved as: capture_13_20251005_025219.jpg\n",
      "âœ… NEW prediction updated: tired-person (0.706)\n",
      "--------------------------------------------------\n",
      "\n",
      "ğŸ“¸ Capture #14 - Running test...\n",
      "ğŸ’¾ Saved image: /Users/u464645/Documents/projects/hackatons/project/sample/webcam_captures/capture_14_20251005_025221.jpg\n",
      "\n",
      "1 happy-person, 1 tired-person\n",
      "Latency: imload 2ms, preprocess 1ms, inference 24ms, postprocess 0ms, total 27ms\n",
      "{'detections': [FocoosDet(bbox=None, conf=0.6092157959938049, cls_id=0, label=happy-person, mask=None, keypoints=None), FocoosDet(bbox=None, conf=0.7496537566184998, cls_id=1, label=tired-person, mask=None, keypoints=None)], 'image': None, 'latency': InferLatency(imload=0.002, preprocess=0.001, inference=0.024, postprocess=0.0, annotate=None)}\n",
      "   âœ… Prediction: tired-person (confidence: 0.750)\n",
      "â±ï¸  Inference time: 27.9 ms\n",
      "ğŸ’¾ Image saved as: capture_14_20251005_025221.jpg\n",
      "âœ… NEW prediction updated: tired-person (0.750)\n",
      "--------------------------------------------------\n",
      "\n",
      "ğŸ“¸ Capture #15 - Running test...\n",
      "ğŸ’¾ Saved image: /Users/u464645/Documents/projects/hackatons/project/sample/webcam_captures/capture_15_20251005_025221.jpg\n",
      "\n",
      "1 happy-person, 1 tired-person\n",
      "Latency: imload 3ms, preprocess 2ms, inference 24ms, postprocess 0ms, total 29ms\n",
      "{'detections': [FocoosDet(bbox=None, conf=0.7163106203079224, cls_id=0, label=happy-person, mask=None, keypoints=None), FocoosDet(bbox=None, conf=0.6718919277191162, cls_id=1, label=tired-person, mask=None, keypoints=None)], 'image': None, 'latency': InferLatency(imload=0.003, preprocess=0.002, inference=0.024, postprocess=0.0, annotate=None)}\n",
      "   âœ… Prediction: tired-person (confidence: 0.672)\n",
      "â±ï¸  Inference time: 28.5 ms\n",
      "ğŸ’¾ Image saved as: capture_15_20251005_025221.jpg\n",
      "âœ… NEW prediction updated: tired-person (0.672)\n",
      "--------------------------------------------------\n",
      "\n",
      "ğŸ“¸ Capture #16 - Running test...\n",
      "ğŸ’¾ Saved image: /Users/u464645/Documents/projects/hackatons/project/sample/webcam_captures/capture_16_20251005_025221.jpg\n",
      "\n",
      "1 happy-person, 1 tired-person\n",
      "Latency: imload 2ms, preprocess 2ms, inference 22ms, postprocess 0ms, total 26ms\n",
      "{'detections': [FocoosDet(bbox=None, conf=0.6686655282974243, cls_id=0, label=happy-person, mask=None, keypoints=None), FocoosDet(bbox=None, conf=0.708593487739563, cls_id=1, label=tired-person, mask=None, keypoints=None)], 'image': None, 'latency': InferLatency(imload=0.002, preprocess=0.002, inference=0.022, postprocess=0.0, annotate=None)}\n",
      "   âœ… Prediction: tired-person (confidence: 0.709)\n",
      "â±ï¸  Inference time: 26.2 ms\n",
      "ğŸ’¾ Image saved as: capture_16_20251005_025221.jpg\n",
      "âœ… NEW prediction updated: tired-person (0.709)\n",
      "--------------------------------------------------\n",
      "\n",
      "ğŸ“¸ Capture #17 - Running test...\n",
      "ğŸ’¾ Saved image: /Users/u464645/Documents/projects/hackatons/project/sample/webcam_captures/capture_17_20251005_025222.jpg\n",
      "\n",
      "1 happy-person, 1 tired-person\n",
      "Latency: imload 3ms, preprocess 1ms, inference 24ms, postprocess 0ms, total 28ms\n",
      "{'detections': [FocoosDet(bbox=None, conf=0.6661137938499451, cls_id=0, label=happy-person, mask=None, keypoints=None), FocoosDet(bbox=None, conf=0.7050344944000244, cls_id=1, label=tired-person, mask=None, keypoints=None)], 'image': None, 'latency': InferLatency(imload=0.003, preprocess=0.001, inference=0.024, postprocess=0.0, annotate=None)}\n",
      "   âœ… Prediction: tired-person (confidence: 0.705)\n",
      "â±ï¸  Inference time: 28.4 ms\n",
      "ğŸ’¾ Image saved as: capture_17_20251005_025222.jpg\n",
      "âœ… NEW prediction updated: tired-person (0.705)\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-05 02:52:24.135 python[38289:11955490] _TIPropertyValueIsValid called with 16 on nil context!\n",
      "2025-10-05 02:52:24.135 python[38289:11955490] imkxpc_getApplicationProperty:reply: called with incorrect property value 16, bailing.\n",
      "2025-10-05 02:52:24.135 python[38289:11955490] Text input context does not respond to _valueForTIProperty:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“¸ Capture #18 - Running test...\n",
      "ğŸ’¾ Saved image: /Users/u464645/Documents/projects/hackatons/project/sample/webcam_captures/capture_18_20251005_025246.jpg\n",
      "\n",
      "1 happy-person, 1 tired-person\n",
      "Latency: imload 3ms, preprocess 1ms, inference 26ms, postprocess 0ms, total 30ms\n",
      "{'detections': [FocoosDet(bbox=None, conf=0.6320154666900635, cls_id=0, label=happy-person, mask=None, keypoints=None), FocoosDet(bbox=None, conf=0.7551708817481995, cls_id=1, label=tired-person, mask=None, keypoints=None)], 'image': None, 'latency': InferLatency(imload=0.003, preprocess=0.001, inference=0.026, postprocess=0.0, annotate=None)}\n",
      "   âœ… Prediction: tired-person (confidence: 0.755)\n",
      "â±ï¸  Inference time: 29.6 ms\n",
      "ğŸ’¾ Image saved as: capture_18_20251005_025246.jpg\n",
      "âœ… NEW prediction updated: tired-person (0.755)\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-05 02:52:48.537 python[38289:11955490] _TIPropertyValueIsValid called with 16 on nil context!\n",
      "2025-10-05 02:52:48.537 python[38289:11955490] imkxpc_getApplicationProperty:reply: called with incorrect property value 16, bailing.\n",
      "2025-10-05 02:52:48.537 python[38289:11955490] Text input context does not respond to _valueForTIProperty:\n",
      "2025-10-05 02:52:54.066 python[38289:11955490] _TIPropertyValueIsValid called with 16 on nil context!\n",
      "2025-10-05 02:52:54.066 python[38289:11955490] imkxpc_getApplicationProperty:reply: called with incorrect property value 16, bailing.\n",
      "2025-10-05 02:52:54.066 python[38289:11955490] Text input context does not respond to _valueForTIProperty:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“¸ Capture #19 - Running test...\n",
      "ğŸ’¾ Saved image: /Users/u464645/Documents/projects/hackatons/project/sample/webcam_captures/capture_19_20251005_025255.jpg\n",
      "\n",
      "1 happy-person, 1 tired-person\n",
      "Latency: imload 2ms, preprocess 1ms, inference 21ms, postprocess 0ms, total 24ms\n",
      "{'detections': [FocoosDet(bbox=None, conf=0.6968820095062256, cls_id=0, label=happy-person, mask=None, keypoints=None), FocoosDet(bbox=None, conf=0.7229427099227905, cls_id=1, label=tired-person, mask=None, keypoints=None)], 'image': None, 'latency': InferLatency(imload=0.002, preprocess=0.001, inference=0.021, postprocess=0.0, annotate=None)}\n",
      "   âœ… Prediction: tired-person (confidence: 0.723)\n",
      "â±ï¸  Inference time: 24.3 ms\n",
      "ğŸ’¾ Image saved as: capture_19_20251005_025255.jpg\n",
      "âœ… NEW prediction updated: tired-person (0.723)\n",
      "--------------------------------------------------\n",
      "\n",
      "ğŸ“¸ Capture #20 - Running test...\n",
      "ğŸ’¾ Saved image: /Users/u464645/Documents/projects/hackatons/project/sample/webcam_captures/capture_20_20251005_025255.jpg\n",
      "\n",
      "1 happy-person, 1 tired-person\n",
      "Latency: imload 3ms, preprocess 1ms, inference 24ms, postprocess 0ms, total 28ms\n",
      "{'detections': [FocoosDet(bbox=None, conf=0.687501072883606, cls_id=0, label=happy-person, mask=None, keypoints=None), FocoosDet(bbox=None, conf=0.719687819480896, cls_id=1, label=tired-person, mask=None, keypoints=None)], 'image': None, 'latency': InferLatency(imload=0.003, preprocess=0.001, inference=0.024, postprocess=0.0, annotate=None)}\n",
      "   âœ… Prediction: tired-person (confidence: 0.720)\n",
      "â±ï¸  Inference time: 27.6 ms\n",
      "ğŸ’¾ Image saved as: capture_20_20251005_025255.jpg\n",
      "âœ… NEW prediction updated: tired-person (0.720)\n",
      "--------------------------------------------------\n",
      "\n",
      "ğŸ“¸ Capture #21 - Running test...\n",
      "ğŸ’¾ Saved image: /Users/u464645/Documents/projects/hackatons/project/sample/webcam_captures/capture_21_20251005_025256.jpg\n",
      "\n",
      "1 happy-person, 1 tired-person\n",
      "Latency: imload 2ms, preprocess 1ms, inference 23ms, postprocess 0ms, total 26ms\n",
      "{'detections': [FocoosDet(bbox=None, conf=0.7278336882591248, cls_id=0, label=happy-person, mask=None, keypoints=None), FocoosDet(bbox=None, conf=0.6999232172966003, cls_id=1, label=tired-person, mask=None, keypoints=None)], 'image': None, 'latency': InferLatency(imload=0.002, preprocess=0.001, inference=0.023, postprocess=0.0, annotate=None)}\n",
      "   âœ… Prediction: tired-person (confidence: 0.700)\n",
      "â±ï¸  Inference time: 26.3 ms\n",
      "ğŸ’¾ Image saved as: capture_21_20251005_025256.jpg\n",
      "âœ… NEW prediction updated: tired-person (0.700)\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 31\u001b[39m\n\u001b[32m     28\u001b[39m \u001b[38;5;66;03m# Example usage:\u001b[39;00m\n\u001b[32m     29\u001b[39m \u001b[38;5;66;03m#classes = {\"background\": 1,\"humans\": 2}\u001b[39;00m\n\u001b[32m     30\u001b[39m classes = {\u001b[33m\"\u001b[39m\u001b[33mhappy-person\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m1\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33mtired-person\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m2\u001b[39m}\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m \u001b[43minteractive_webcam_tester\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclasses\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtired-person\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mworkspace_root\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 35\u001b[39m, in \u001b[36minteractive_webcam_tester\u001b[39m\u001b[34m(model, classes, preferred_label, workspace_root, window_name)\u001b[39m\n\u001b[32m     32\u001b[39m processing_start = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m     ret, frame = \u001b[43mcap\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     36\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ret:\n\u001b[32m     37\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mâš ï¸ Failed to grab frame.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from focoos import ModelManager, FocoosHUB\n",
    "from focoos.models.focoos_model  import FocoosModel, FocoosDetections\n",
    "import os\n",
    "api_key = os.environ.get(\"FOCOOS_API_KEY\") or 'c7ef8380320c421792425668205fa8fa'\n",
    "\n",
    "hub = FocoosHUB(api_key=api_key)\n",
    "\n",
    "ref = \"f73c51dfb3bd422f\"\n",
    "model : FocoosModel= ModelManager.get(f\"hub://{ref}\", hub=hub)\n",
    "\n",
    "\n",
    "# ğŸ¯ Verify HUB Model for Tired Person Detection\n",
    "print(\"ğŸ” HUB Model Status:\")\n",
    "if 'model' in locals() and model is not None:\n",
    "    print(f\"âœ… HUB Model loaded: {type(model)}\")\n",
    "    \n",
    "    # Test with dummy input to check classes\n",
    "    try:\n",
    "        import numpy as np\n",
    "        dummy_input = np.random.rand(224, 224, 3).astype(np.uint8)\n",
    "        dummy_pil = Image.fromarray(dummy_input)\n",
    "        test_result : FocoosDetections = model(dummy_pil)\n",
    "\n",
    "        pred= test_result\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸  Could not test model: {e}\")\n",
    "        \n",
    "# Example usage:\n",
    "#classes = {\"background\": 1,\"humans\": 2}\n",
    "classes = {\"happy-person\": 1,\"tired-person\": 2}\n",
    "interactive_webcam_tester(model, classes, \"tired-person\", workspace_root)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "focoos-sample-app",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
